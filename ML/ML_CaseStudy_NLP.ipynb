{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML CaseStudy-NLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "80Mt2GsdtBZH"
      },
      "source": [
        "# Case Study - NLP"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLZ3yXIIt9pF"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import nltk\r\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CR6AFxtYu50M",
        "outputId": "547d0b39-551a-4613-e827-89ff123dbc85"
      },
      "source": [
        "nltk.download('punkt')\r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge0lDGYGtd9B"
      },
      "source": [
        "# 1.a) Create a function named ‘tokenized_text ()’that takes ‘sentence’ as its argument and performs\r\n",
        "# word tokenization and removes all stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voesbYR9uG2p"
      },
      "source": [
        "stop_words = set(stopwords.words(\"english\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2TNxpzGteAa"
      },
      "source": [
        "def tokenizedText(sentences1):\r\n",
        "  sentence = nltk.word_tokenize(sentences1)\r\n",
        "  #print(\"Sentences  :\", sentences1)\r\n",
        "  #print(\"\\n sentence  :\", sentence)\r\n",
        "  cleanedText = [w.lower() for w in sentence if w not in stop_words]\r\n",
        "\r\n",
        "  return cleanedText"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PCh8TclwOQS"
      },
      "source": [
        "# 1.b) Create a function named ‘sorted_token ()’ that takes ‘sentence’ as its argument and removes\r\n",
        "# the duplicate word tokens and returns a sorted list of word tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_gNSfMuwzX8"
      },
      "source": [
        "def sortedToken(sentence2):\r\n",
        "  wordTokens = []\r\n",
        " \r\n",
        "  for sent in sentence2:\r\n",
        "    wordList = tokenizedText(sent)\r\n",
        "    wordTokens.extend(wordList)\r\n",
        "    # print(wordList)\r\n",
        "    # print(\"sortedToken  :\",wordTokens)\r\n",
        "\r\n",
        "  wordTokens = sorted(list(set(wordTokens)))\r\n",
        "  print(\"sortedTokens  :\",wordTokens)\r\n",
        "  \r\n",
        "  return wordTokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTFI2ylpuHAa",
        "outputId": "475a1f94-3bd5-4614-a86b-9dcda5c20e47"
      },
      "source": [
        "sentenceList = [\"John likes to watch movies\",\r\n",
        "                \"Mary likes to play football\",\r\n",
        "                \"John likes to watch football games but does not like to play football\",\r\n",
        "                \"Both John and Mary like to play video games\"]\r\n",
        "sentences1 = \"John likes to watch football games but does not like to play football\"\r\n",
        "text1 = sortedToken(sentenceList)\r\n",
        "print(\"Cleaned Text : \",text1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentences  : John likes to watch movies\n",
            "\n",
            " sentence  : ['John', 'likes', 'to', 'watch', 'movies']\n",
            "Sentences  : Mary likes to play football\n",
            "\n",
            " sentence  : ['Mary', 'likes', 'to', 'play', 'football']\n",
            "Sentences  : John likes to watch football games but does not like to play football\n",
            "\n",
            " sentence  : ['John', 'likes', 'to', 'watch', 'football', 'games', 'but', 'does', 'not', 'like', 'to', 'play', 'football']\n",
            "Sentences  : Both John and Mary like to play video games\n",
            "\n",
            " sentence  : ['Both', 'John', 'and', 'Mary', 'like', 'to', 'play', 'video', 'games']\n",
            "sortedToken 1 : ['both', 'football', 'games', 'john', 'like', 'likes', 'mary', 'movies', 'play', 'video', 'watch']\n",
            "Cleaned Text :  ['both', 'football', 'games', 'john', 'like', 'likes', 'mary', 'movies', 'play', 'video', 'watch']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4WLkGqmtQ_i"
      },
      "source": [
        "# 1.c) Create a function named ‘bag_of_word ()’ that takes ‘sentence’ and ‘word’ as its arguments,\r\n",
        "# calculates the frequency word count of word tokens, and returns a NumPy array of word tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOMsHQgLtXVY"
      },
      "source": [
        "def bagofWords(sentence1, words1): \r\n",
        "  wordsList = tokenizedText(sentence1)\r\n",
        "  #print(type(wordsList))\r\n",
        "  print(\"words list :\",wordsList, \"\\n Vocubulary/SortedToken :\",words1)\r\n",
        "  wordBag = np.zeros(len(words1))\r\n",
        "  for w in wordsList:\r\n",
        "    for j, word in enumerate(words1):\r\n",
        "      if w == word:\r\n",
        "        wordBag[j] += 1\r\n",
        "  \r\n",
        "  return np.array(wordBag)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5uDRg9xQ8Lp"
      },
      "source": [
        "# 1.d) Create a bag-of-words model on the following sentences using the three functions defined above:\r\n",
        "# Joe went to the store\r\n",
        "# Joe wants to buy a dining set\r\n",
        "# Joe met John at the store\r\n",
        "# Joe and John are best friends"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sy8P25PjvRS2"
      },
      "source": [
        "sentenceList1 = [\"Joe went to the store\",\r\n",
        "                  \"Joe wants to buy a dining set\",\r\n",
        "                  \"Joe met John at the store\",\r\n",
        "                  \"Joe and John are best friends\"]\r\n",
        "                  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oi3WxPHLw0i1",
        "outputId": "bf2abce1-8214-48fb-e12e-1bfd5266c2f2"
      },
      "source": [
        "sentences1 = \"John likes to watch football games but does not like to play football\"\r\n",
        "vocu = sortedToken(sentenceList1)\r\n",
        "#print(\"Cleaned Text : \",text1)\r\n",
        "bag = bagofWords(sentences1,vocu)\r\n",
        "print(\"Bag of words array : \",bag)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sortedToken  : ['best', 'buy', 'dining', 'friends', 'joe', 'john', 'met', 'set', 'store', 'wants', 'went']\n",
            "words list : ['john', 'likes', 'watch', 'football', 'games', 'like', 'play', 'football'] \n",
            " Vocubulary/SortedToken : ['best', 'buy', 'dining', 'friends', 'joe', 'john', 'met', 'set', 'store', 'wants', 'went']\n",
            "Bag of words array :  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwHoansxRznb"
      },
      "source": [
        "# Assignment for CountVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPayCAGMR1ZI"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHo17ZC1bUgw"
      },
      "source": [
        "# 2.b) Create a numpy array named ‘corpus’ that contains the following sentences:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsDkmy3PR1dt",
        "outputId": "120a51e6-cdc3-4c95-f4df-1c9a851cafde"
      },
      "source": [
        "corpus = [\"Joe went to the store\",\r\n",
        "          \"Joe wants to buy a dining set\",\r\n",
        "          \"Joe met John at the store\",\r\n",
        "          \"Joe and John are best friends\"]\r\n",
        "corpus = np.array(corpus)\r\n",
        "corpus"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Joe went to the store', 'Joe wants to buy a dining set',\n",
              "       'Joe met John at the store', 'Joe and John are best friends'],\n",
              "      dtype='<U29')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdaeSCUrbbc4"
      },
      "source": [
        "# 2.c) Use the ‘CountVectorizer’ class object to fit and transform the text present in ‘corpus’ and\r\n",
        "# store the result in ‘bag_of_words’"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrm0yxGnbbsm"
      },
      "source": [
        "countVector = CountVectorizer(stop_words=stop_words)\r\n",
        "\r\n",
        "bagofWords = countVector.fit_transform(corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2qi6oz6dgMC",
        "outputId": "c3a8ae88-efac-491e-fb28-08cca7fe02a8"
      },
      "source": [
        "# 2.d) Print ‘bag_of_words’ as a numpy array\r\n",
        "\r\n",
        "bagofWords = bagofWords.toarray()\r\n",
        "\r\n",
        "print(\"Bag of Words :\", bagofWords)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bag of Words : [[0 0 0 0 1 0 0 0 1 0 1]\n",
            " [0 1 1 0 1 0 0 1 0 1 0]\n",
            " [0 0 0 0 1 1 1 0 1 0 0]\n",
            " [1 0 0 1 1 1 0 0 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6x3YCA08dgPp",
        "outputId": "98fed335-3b83-476b-baf2-0478ebd273d5"
      },
      "source": [
        "# 2.e) Print all feature names of the above-created ‘CountVectorizer’ object\r\n",
        "\r\n",
        "featureNames = countVector.get_feature_names()\r\n",
        "\r\n",
        "print(\"Feature Names :\", featureNames)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature Names : ['best', 'buy', 'dining', 'friends', 'joe', 'john', 'met', 'set', 'store', 'wants', 'went']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "TJOcMwvLfv7V",
        "outputId": "51e2c557-2eb0-4290-b897-373c3c4e1e0f"
      },
      "source": [
        "# 2.f) Print the ‘bag_of_words’ array as a Pandas Data Frame with column names as feature names\r\n",
        "\r\n",
        "pd.DataFrame(bagofWords, columns = featureNames)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>best</th>\n",
              "      <th>buy</th>\n",
              "      <th>dining</th>\n",
              "      <th>friends</th>\n",
              "      <th>joe</th>\n",
              "      <th>john</th>\n",
              "      <th>met</th>\n",
              "      <th>set</th>\n",
              "      <th>store</th>\n",
              "      <th>wants</th>\n",
              "      <th>went</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   best  buy  dining  friends  joe  john  met  set  store  wants  went\n",
              "0     0    0       0        0    1     0    0    0      1      0     1\n",
              "1     0    1       1        0    1     0    0    1      0      1     0\n",
              "2     0    0       0        0    1     1    1    0      1      0     0\n",
              "3     1    0       0        1    1     1    0    0      0      0     0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh7cMUqJg-_s"
      },
      "source": [
        "# 3. Assignment for Term Frequency–Inverse Document Frequency"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hhDYXjSg_EA"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvziTE5njHLb",
        "outputId": "cc5a8267-97d4-458b-ef3d-def3363c8fd5"
      },
      "source": [
        "# 3.b) Create a numpy array named ‘corpus’ that contains the following sentences:\r\n",
        "# Joe went to the store, Joe wants to buy a dining set, Joe met John at the store, Joe and John are best friends\r\n",
        "\r\n",
        "corpus = [\"Joe went to the store\", \r\n",
        "           \"Joe wants to buy a dining set\", \r\n",
        "           \"Joe met John at the store\", \r\n",
        "           \"Joe and John are best friends\"]\r\n",
        "corpus3 = np.array(corpus)\r\n",
        "corpus3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Joe went to the store', 'Joe wants to buy a dining set',\n",
              "       'Joe met John at the store', 'Joe and John are best friends'],\n",
              "      dtype='<U29')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAmpVEYVjbqO"
      },
      "source": [
        "# 3.c) Use the ‘TfidfVectorizer’ class to create an object to fit and transform the text present in\r\n",
        "# ‘corpus’ created above and store the result in ‘bag_of_words’\r\n",
        "\r\n",
        "tfIDVector = TfidfVectorizer(stop_words = stop_words)\r\n",
        "\r\n",
        "bagofWords3 = tfIDVector.fit_transform(corpus3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jxd1ILJxjbvY",
        "outputId": "1bdc2df6-cf62-408c-95a4-81e0230f0e83"
      },
      "source": [
        "# 3.d) Print ‘bag_of_words’ as a numpy array\r\n",
        "\r\n",
        "bagofWords3 = bagofWords3.toarray()\r\n",
        "\r\n",
        "print(\"Bag of Words :\", bagofWords3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bag of Words : [[0.         0.         0.         0.         0.37919167 0.\n",
            "  0.         0.         0.5728925  0.         0.72664149]\n",
            " [0.         0.48380259 0.48380259 0.         0.25246826 0.\n",
            "  0.         0.48380259 0.         0.48380259 0.        ]\n",
            " [0.         0.         0.         0.         0.32902288 0.4970962\n",
            "  0.6305035  0.         0.4970962  0.         0.        ]\n",
            " [0.58783765 0.         0.         0.58783765 0.30675807 0.46345796\n",
            "  0.         0.         0.         0.         0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHLR_BBAjbzc",
        "outputId": "9fe26c4a-38fc-4e93-b812-a89f2acf85f5"
      },
      "source": [
        "# 3.e) Print all feature names of the above-created ‘TfidfVectorizer’ object\r\n",
        "\r\n",
        "featureNames3 = tfIDVector.get_feature_names()\r\n",
        "\r\n",
        "print(\"Feature Names :\", featureNames3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature Names : ['best', 'buy', 'dining', 'friends', 'joe', 'john', 'met', 'set', 'store', 'wants', 'went']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "-khiazrXlQ4W",
        "outputId": "58b92bbe-fe5a-405e-e360-5301ce95cddc"
      },
      "source": [
        "# 3.f) Print the ‘bag_of_words’ array as a pandas data frame with column names as feature names\r\n",
        "\r\n",
        "pd.DataFrame(bagofWords3, columns = featureNames3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>best</th>\n",
              "      <th>buy</th>\n",
              "      <th>dining</th>\n",
              "      <th>friends</th>\n",
              "      <th>joe</th>\n",
              "      <th>john</th>\n",
              "      <th>met</th>\n",
              "      <th>set</th>\n",
              "      <th>store</th>\n",
              "      <th>wants</th>\n",
              "      <th>went</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.379192</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.572892</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.726641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.483803</td>\n",
              "      <td>0.483803</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.252468</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.483803</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.483803</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.329023</td>\n",
              "      <td>0.497096</td>\n",
              "      <td>0.630504</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.497096</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.587838</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.587838</td>\n",
              "      <td>0.306758</td>\n",
              "      <td>0.463458</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       best       buy    dining  ...     store     wants      went\n",
              "0  0.000000  0.000000  0.000000  ...  0.572892  0.000000  0.726641\n",
              "1  0.000000  0.483803  0.483803  ...  0.000000  0.483803  0.000000\n",
              "2  0.000000  0.000000  0.000000  ...  0.497096  0.000000  0.000000\n",
              "3  0.587838  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "\n",
              "[4 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    }
  ]
}